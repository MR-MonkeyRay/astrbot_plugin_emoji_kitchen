import os
import json
import asyncio
import hashlib
import time
from pathlib import Path
from collections import OrderedDict

import regex
import aiohttp

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger

# ===== å¸¸é‡ =====
HARDCODED_DATES = [
    "20251029", "20250501", "20250430", "20250204", "20250130",
    "20241023", "20241021", "20240610", "20240530", "20240214",
    "20240206", "20231128", "20231113", "20230821", "20230818",
    "20230803", "20230426", "20230418", "20230301", "20230216",
    "20230127", "20230126", "20221107", "20221101", "20220815",
    "20220506", "20220406", "20220203", "20220110", "20211115",
    "20210831", "20210521", "20210218", "20201001",
]

EMOJI_PATTERN = regex.compile(
    r'\p{Extended_Pictographic}'
    r'(?:\ufe0f|\ufe0e)?'
    r'(?:[\U0001F3FB-\U0001F3FF])?'
    r'(?:\u200d\p{Extended_Pictographic}'
    r'(?:\ufe0f|\ufe0e)?'
    r'(?:[\U0001F3FB-\U0001F3FF])?)*',
    regex.UNICODE
)

# ===== å¼‚å¸¸ =====
class RateLimitError(Exception):
    """CDN é™æµå¼‚å¸¸ï¼Œéœ€è¦ç«‹å³åœæ­¢æ¢æµ‹"""
    pass

# ===== å·¥å…·å‡½æ•° =====
def emoji_to_codepoint(emoji_str: str) -> str:
    """å°† emoji å­—ç¬¦ä¸²è½¬ä¸º codepoint æ ¼å¼ã€‚
    ğŸ˜€ â†’ '1f600', â¤ï¸ â†’ '2764-fe0f'
    """
    return "-".join(f"{ord(c):x}" for c in emoji_str)

def codepoint_to_url_segment(cp: str) -> str:
    """å°† codepoint è½¬ä¸º URL è·¯å¾„æ®µã€‚
    '1f600' â†’ 'u1f600', '2764-fe0f' â†’ 'u2764-ufe0f'
    """
    return "-".join(f"u{part}" for part in cp.split("-"))

def make_cache_key(cp1: str, cp2: str) -> str:
    """ç”Ÿæˆæ’åºåçš„ç¼“å­˜ keyã€‚ä¿è¯ A+B ä¸ B+A å‘½ä¸­åŒä¸€ç¼“å­˜ã€‚"""
    return "_".join(sorted([cp1, cp2]))

# ===== æ’ä»¶ä¸»ç±» =====
@register("astrbot_plugin_emoji_kitchen", "monkeyray", "å‘é€ä¸¤ä¸ª emoji è‡ªåŠ¨åˆæˆ Google Emoji Kitchen å›¾ç‰‡", "1.0.0")
class EmojiKitchenPlugin(Star):
    _MAX_LOCKS = 1024
    _CONCURRENT_LIMIT = 4

    def __init__(self, context: Context, config: dict | None = None):
        super().__init__(context)
        self.config = config or {}
        self.data_dir: Path = Path("")
        self.cache_dir: Path = Path("")
        self.notfound_dir: Path = Path("")
        self.dates_cache_path: Path = Path("")
        self.date_list: list[str] = []
        self._locks: OrderedDict[str, asyncio.Lock] = OrderedDict()
        self._global_lock = asyncio.Lock()
        self._session_lock = asyncio.Lock()
        self._session: aiohttp.ClientSession | None = None
        self._semaphore: asyncio.Semaphore | None = None
        self._update_task: asyncio.Task | None = None

    async def initialize(self):
        """æ’ä»¶åˆå§‹åŒ–ï¼šåˆ›å»ºç›®å½•ã€åŠ è½½é…ç½®ã€å¯åŠ¨æ—¥æœŸæ›´æ–°"""
        self.data_dir = Path(self.context.get_data_dir())
        self.cache_dir = self.data_dir / "cache"
        self.notfound_dir = self.data_dir / "notfound"
        self.dates_cache_path = self.data_dir / "dates_cache.json"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.notfound_dir.mkdir(parents=True, exist_ok=True)
        # åˆå§‹åŒ– semaphore
        self._semaphore = asyncio.Semaphore(self._CONCURRENT_LIMIT)
        # é¢„åˆ›å»º session
        await self._ensure_session()
        # åŠ è½½æ—¥æœŸåˆ—è¡¨
        self._load_date_list()
        # å¼‚æ­¥æ›´æ–°è¿œç¨‹æ—¥æœŸï¼ˆä¸é˜»å¡åˆå§‹åŒ–ï¼‰
        self._update_task = asyncio.create_task(self._update_dates_from_remote())
        logger.info(f"Emoji Kitchen æ’ä»¶åˆå§‹åŒ–å®Œæˆï¼Œæ—¥æœŸåˆ—è¡¨: {len(self.date_list)} ä¸ª")

    async def _ensure_session(self) -> aiohttp.ClientSession:
        """ç¡®ä¿ session å•ä¾‹å­˜åœ¨ï¼ˆåŒé‡æ£€æŸ¥é”ï¼‰"""
        if self._session and not self._session.closed:
            return self._session
        async with self._session_lock:
            if self._session and not self._session.closed:
                return self._session
            self._session = aiohttp.ClientSession(
                connector=aiohttp.TCPConnector(limit=20, ttl_dns_cache=300)
            )
            return self._session

    def _get_config(self, key: str, default=None):
        """ä»æ’ä»¶é…ç½®ä¸­è·å–å€¼"""
        if self.config and key in self.config:
            return self.config[key]
        return default

    def _resolve_cdn_url(self) -> str:
        """è§£æå®é™…çš„ CDN åœ°å€ï¼šä¼˜å…ˆ cdn_source é¢„è®¾ï¼Œè‡ªå®šä¹‰æ—¶ç”¨ cdn_url"""
        source = str(self._get_config("cdn_source", "") or "")
        if source.startswith("www.gstatic.cn"):
            return "https://www.gstatic.cn"
        elif source.startswith("www.gstatic.com"):
            return "https://www.gstatic.com"
        elif source == "è‡ªå®šä¹‰":
            custom = str(self._get_config("cdn_url", "") or "").strip().rstrip("/")
            if custom:
                return custom
        elif not source:
            # å…¼å®¹æ—§é…ç½®ï¼šcdn_source ä¸ºç©ºæ—¶æ£€æŸ¥æ—§çš„ cdn_url å­—æ®µ
            legacy = str(self._get_config("cdn_url", "") or "").strip().rstrip("/")
            if legacy:
                return legacy
        # é»˜è®¤ï¼ˆç©ºæˆ–æœªè¯†åˆ«ï¼‰ï¼šè¿”å› gstatic.cn
        return "https://www.gstatic.cn"

    def _resolve_github_proxy(self) -> str:
        """è§£æå®é™…çš„ GitHub ä»£ç†åœ°å€ï¼šè¿”å›ä»£ç† URL æˆ–ç©ºå­—ç¬¦ä¸²ï¼ˆç›´è¿ï¼‰"""
        source = str(self._get_config("github_proxy_source", "") or "")
        if source.startswith("ghfast.top"):
            return "https://ghfast.top"
        elif source.startswith("gh-proxy.com"):
            return "https://gh-proxy.com"
        elif source == "è‡ªå®šä¹‰":
            custom = str(self._get_config("github_proxy", "") or "").strip().rstrip("/")
            if custom:
                return custom
        elif source == "ä¸ä½¿ç”¨ä»£ç†":
            return ""
        elif not source:
            # å…¼å®¹æ—§é…ç½®ï¼šgithub_proxy_source ä¸ºç©ºæ—¶æ£€æŸ¥æ—§çš„ github_proxy å­—æ®µ
            legacy = str(self._get_config("github_proxy", "") or "").strip().rstrip("/")
            if legacy:
                return legacy
        # é»˜è®¤ï¼ˆç©ºæˆ–æœªè¯†åˆ«ï¼‰ï¼šè¿”å› ghfast.top
        return "https://ghfast.top"

    def _get_cached_image(self, cache_key: str) -> str | None:
        """æ£€æŸ¥ç¼“å­˜å›¾ç‰‡æ˜¯å¦å­˜åœ¨ï¼Œè¿”å›è·¯å¾„æˆ– None"""
        path = self.cache_dir / f"{cache_key}.png"
        if path.exists():
            return str(path)
        return None

    def _is_notfound(self, cache_key: str) -> bool:
        """æ£€æŸ¥ notfound æ ‡è®°æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ"""
        path = self.notfound_dir / f"{cache_key}.json"
        if not path.exists():
            return False
        try:
            with open(path, encoding="utf-8") as f:
                data = json.load(f)
            # æ£€æŸ¥è¿‡æœŸ
            expire_days = self._get_config("notfound_expire_days", 7)
            if time.time() - data.get("timestamp", 0) > expire_days * 86400:
                path.unlink(missing_ok=True)
                return False
            # æ£€æŸ¥æ—¥æœŸåˆ—è¡¨æ˜¯å¦å˜åŒ–
            current_hash = self._get_date_list_hash()
            if data.get("date_list_hash") != current_hash:
                path.unlink(missing_ok=True)
                return False
            return True
        except (json.JSONDecodeError, KeyError, OSError, TypeError, ValueError):
            path.unlink(missing_ok=True)
            return False

    def _write_notfound(self, cache_key: str, dates_tried: int):
        """å†™å…¥ notfound æ ‡è®°ï¼ˆJSON æ ¼å¼ï¼‰"""
        path = self.notfound_dir / f"{cache_key}.json"
        data = {
            "timestamp": int(time.time()),
            "dates_tried": dates_tried,
            "date_list_hash": self._get_date_list_hash(),
        }
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(data, f)
        except OSError as e:
            logger.warning(f"å†™å…¥ notfound æ ‡è®°å¤±è´¥: {e}")

    def _save_image_atomic(self, cache_key: str, data: bytes) -> str:
        """åŸå­å†™å…¥ç¼“å­˜å›¾ç‰‡ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶å† rename"""
        target = self.cache_dir / f"{cache_key}.png"
        tmp_path = self.cache_dir / f"{cache_key}.tmp"
        try:
            with open(tmp_path, "wb") as f:
                f.write(data)
            os.rename(tmp_path, target)
            return str(target)
        except OSError as e:
            logger.warning(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                tmp_path.unlink(missing_ok=True)
            except OSError:
                pass
            raise

    def _get_date_list_hash(self) -> str:
        """è·å–å½“å‰æ—¥æœŸåˆ—è¡¨çš„ hash"""
        return hashlib.md5(",".join(self.date_list).encode()).hexdigest()[:8]

    def _load_date_list(self):
        """åŠ è½½æ—¥æœŸåˆ—è¡¨ï¼šåˆå¹¶è¿œç¨‹ç¼“å­˜ + ç¡¬ç¼–ç  + extra_datesï¼Œå»é‡åæŒ‰æ—¥æœŸå€’åº"""
        dates = set(HARDCODED_DATES)

        # ä»æœ¬åœ°ç¼“å­˜åŠ è½½
        if self.dates_cache_path.exists():
            try:
                with open(self.dates_cache_path, encoding="utf-8") as f:
                    cached = json.load(f)
                if isinstance(cached, list):
                    dates.update(cached)
            except (json.JSONDecodeError, OSError) as e:
                logger.warning(f"æ—¥æœŸç¼“å­˜åŠ è½½å¤±è´¥: {e}")

        # åˆå¹¶ extra_dates é…ç½®
        extra = self._get_config("extra_dates", "")
        if extra:
            for line in extra.strip().splitlines():
                line = line.strip()
                if line and line.isdigit() and len(line) == 8:
                    dates.add(line)

        self.date_list = sorted(dates, reverse=True)

    async def _update_dates_from_remote(self):
        """ä» GitHub æ‹‰å–æ ·æœ¬æ•°æ®æå–æ—¥æœŸåˆ—è¡¨å¹¶ç¼“å­˜"""
        github_proxy = self._resolve_github_proxy()
        timeout_sec = self._get_config("request_timeout", 10)
        raw_url = "https://raw.githubusercontent.com/xsalazar/emoji-kitchen-backend/main/emoji/data/1f600.json"
        if github_proxy:
            url = f"{github_proxy}/{raw_url}"
        else:
            url = raw_url

        try:
            session = await self._ensure_session()

            async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout_sec)) as resp:
                if resp.status != 200:
                    logger.warning(f"è¿œç¨‹æ—¥æœŸæ‹‰å–å¤±è´¥: HTTP {resp.status}")
                    return
                data = await resp.json(content_type=None)

            # æå–æ‰€æœ‰ date å­—æ®µ
            remote_dates = set()
            if isinstance(data, dict):
                for combo in data.get("combinations", []):
                    if "date" in combo:
                        remote_dates.add(combo["date"])

            if remote_dates:
                # åˆå¹¶åˆ°å·²çŸ¥åˆ—è¡¨å¹¶å†™å…¥ç¼“å­˜
                all_dates = set(HARDCODED_DATES) | remote_dates
                if self.dates_cache_path.exists():
                    try:
                        with open(self.dates_cache_path, encoding="utf-8") as f:
                            existing = json.load(f)
                        if isinstance(existing, list):
                            all_dates.update(existing)
                    except (json.JSONDecodeError, OSError):
                        pass

                sorted_dates = sorted(all_dates, reverse=True)
                with open(self.dates_cache_path, "w", encoding="utf-8") as f:
                    json.dump(sorted_dates, f)

                # é‡æ–°åŠ è½½
                self._load_date_list()
                logger.info(f"æ—¥æœŸåˆ—è¡¨æ›´æ–°æˆåŠŸï¼Œå…± {len(self.date_list)} ä¸ªæ—¥æœŸ")
        except Exception as e:
            logger.warning(f"è¿œç¨‹æ—¥æœŸæ›´æ–°å¤±è´¥: {e}")

    async def _get_lock(self, cache_key: str) -> asyncio.Lock:
        """è·å–æŒ‡å®š cache_key çš„é”ï¼Œç”¨äºå¹¶å‘è¯·æ±‚å»é‡ï¼ˆLRU æ·˜æ±°ï¼‰"""
        async with self._global_lock:
            if cache_key in self._locks:
                self._locks.move_to_end(cache_key)
                return self._locks[cache_key]
            lock = asyncio.Lock()
            self._locks[cache_key] = lock
            while len(self._locks) > self._MAX_LOCKS:
                self._locks.popitem(last=False)
            return lock

    def _build_urls(self, cp1: str, cp2: str, date: str) -> list[str]:
        """ä¸ºç»™å®šæ—¥æœŸæ„é€ ä¸¤ä¸ªæ–¹å‘çš„ URLï¼ˆAâ†’B å’Œ Bâ†’Aï¼‰"""
        cdn_url = self._resolve_cdn_url()
        seg1 = codepoint_to_url_segment(cp1)
        seg2 = codepoint_to_url_segment(cp2)
        return [
            f"{cdn_url}/android/keyboard/emojikitchen/{date}/{seg1}/{seg1}_{seg2}.png",
            f"{cdn_url}/android/keyboard/emojikitchen/{date}/{seg2}/{seg2}_{seg1}.png",
        ]

    async def _try_fetch_url(self, url: str) -> bytes | None:
        """å°è¯•è¯·æ±‚å•ä¸ª URLã€‚è¿”å› None ä»…è¡¨ç¤ºç¡®è®¤ 404ï¼Œå…¶ä»–å¤±è´¥å‡ raiseã€‚"""
        timeout_sec = self._get_config("request_timeout", 10)
        try:
            session = await self._ensure_session()

            async with session.get(
                url, timeout=aiohttp.ClientTimeout(total=timeout_sec)
            ) as resp:
                if resp.status == 404:
                    return None
                if resp.status == 429:
                    logger.warning(f"Emoji Kitchen CDN é™æµ: {url}")
                    raise RateLimitError()
                if resp.status >= 500:
                    logger.warning(f"Emoji Kitchen CDN æœåŠ¡ç«¯é”™è¯¯ {resp.status}: {url}")
                    raise aiohttp.ClientError(f"server error {resp.status}")
                if resp.status != 200:
                    logger.warning(f"Emoji Kitchen æœªé¢„æœŸçŠ¶æ€ç  {resp.status}: {url}")
                    raise aiohttp.ClientError(f"unexpected status {resp.status}")

                data = await resp.read()
                # PNG æ ¡éªŒï¼šæ£€æŸ¥ magic bytes
                if data[:4] != b'\x89PNG':
                    logger.warning(f"Emoji Kitchen å“åº”é PNG æ ¼å¼: {url}")
                    raise aiohttp.ClientError("not PNG")
                return data
        except asyncio.CancelledError:
            raise
        except (RateLimitError, aiohttp.ClientError):
            raise
        except Exception as e:
            logger.warning(f"Emoji Kitchen è¯·æ±‚å¼‚å¸¸: {url} - {e}")
            raise aiohttp.ClientError(str(e))

    async def _try_fetch_with_semaphore(self, url: str) -> bytes | None:
        """å¸¦ semaphore é™æµçš„ URL è¯·æ±‚"""
        async with self._semaphore:
            return await self._try_fetch_url(url)

    async def _fetch_emoji_image(self, cp1: str, cp2: str) -> str | None:
        """å°è¯•ä» CDN è·å–åˆæˆå›¾ç‰‡ï¼Œè¿”å›ç¼“å­˜è·¯å¾„æˆ– None

        ç­–ç•¥ï¼š
        1. å–æ—¥æœŸåˆ—è¡¨å‰ max_probe_dates ä¸ª
        2. æ—¥æœŸä¹‹é—´ä¸²è¡Œï¼ŒåŒä¸€æ—¥æœŸå†…çš„ 2 ä¸ª URL å¹¶å‘
        3. é¦–ä¸ªå‘½ä¸­ç«‹å³è¿”å›ï¼Œä¸ç»§ç»­æ¢æµ‹åç»­æ—¥æœŸ
        4. é‡ 429ï¼ˆRateLimitErrorï¼‰ç«‹å³åœæ­¢æ‰€æœ‰æ¢æµ‹
        5. ç”¨ semaphore é™åˆ¶åŒæ—¶å¤–å‘¼é‡
        """
        cache_key = make_cache_key(cp1, cp2)
        max_probe = self._get_config("max_probe_dates", 10)
        probe_dates = self.date_list[:max_probe]
        if not probe_dates:
            logger.warning("æ—¥æœŸåˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ¢æµ‹")
            return None

        all_404 = True
        has_error = False

        for date in probe_dates:
            urls = self._build_urls(cp1, cp2, date)
            tasks = []
            for url in urls:
                tasks.append(self._try_fetch_with_semaphore(url))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            found_data = None
            should_stop = False
            for r in results:
                if isinstance(r, RateLimitError):
                    all_404 = False
                    has_error = True
                    should_stop = True
                elif isinstance(r, Exception):
                    all_404 = False
                    has_error = True
                elif r is not None:
                    found_data = r

            if found_data:
                try:
                    path = self._save_image_atomic(cache_key, found_data)
                    return path
                except OSError:
                    return None

            if should_stop:
                break

        # notfound åˆ¤å®šé€»è¾‘
        if all_404 and not has_error and max_probe >= len(self.date_list):
            self._write_notfound(cache_key, len(probe_dates))
            logger.info(f"Emoji Kitchen ç»„åˆä¸å­˜åœ¨: {cache_key}")
        elif has_error:
            logger.info(f"Emoji Kitchen æ¢æµ‹å­˜åœ¨ç½‘ç»œé”™è¯¯ï¼Œä¸å†™ notfound: {cache_key}")
        else:
            logger.info(f"Emoji Kitchen æœªå‘½ä¸­ï¼ˆæ¢æµ‹äº† {len(probe_dates)}/{len(self.date_list)} ä¸ªæ—¥æœŸï¼‰: {cache_key}")
        return None

    @filter.event_message_type(filter.EventMessageType.ALL)
    async def on_message(self, event: AstrMessageEvent):
        """ç›‘å¬æ‰€æœ‰æ¶ˆæ¯ï¼Œæ£€æµ‹åŒ emoji å¹¶åˆæˆ"""
        # 1. è·å–çº¯æ–‡æœ¬æ¶ˆæ¯
        msg = event.message_str.strip() if event.message_str else ""
        if not msg:
            return

        # 2. æå– emoji
        emojis = EMOJI_PATTERN.findall(msg)
        if len(emojis) != 2:
            return

        # 3. éªŒè¯æ¶ˆæ¯ä»…åŒ…å«è¿™ä¸¤ä¸ª emojiï¼ˆæ— å¤šä½™å­—ç¬¦ï¼‰
        if "".join(emojis) != msg:
            return

        # 4. è½¬æ¢ codepoint å¹¶ç”Ÿæˆ cache_key
        cp1 = emoji_to_codepoint(emojis[0])
        cp2 = emoji_to_codepoint(emojis[1])
        cache_key = make_cache_key(cp1, cp2)

        # 5. æ£€æŸ¥ç¼“å­˜
        cached = self._get_cached_image(cache_key)
        if cached:
            yield event.image_result(cached)
            event.stop_event()
            return

        # 6. æ£€æŸ¥ notfound æ ‡è®°
        if self._is_notfound(cache_key):
            return

        # 7. ä½¿ç”¨å¹¶å‘é”é˜²æ­¢é‡å¤è¯·æ±‚
        lock = await self._get_lock(cache_key)
        async with lock:
            # åŒé‡æ£€æŸ¥ï¼šè·å–é”åå†æ¬¡æ£€æŸ¥ç¼“å­˜å’Œ notfound
            cached = self._get_cached_image(cache_key)
            if cached:
                yield event.image_result(cached)
                event.stop_event()
                return
            if self._is_notfound(cache_key):
                return

            # 8. ä» CDN è·å–ï¼ˆå¼‚å¸¸å…œåº•ï¼‰
            try:
                path = await self._fetch_emoji_image(cp1, cp2)
                if path:
                    yield event.image_result(path)
                    event.stop_event()
                    return
            except Exception as e:
                logger.error(f"Emoji Kitchen è·å–å¼‚å¸¸: {e}")

        # æœªå‘½ä¸­ï¼šä¸ yieldï¼Œä¸ stop_eventï¼Œäº‹ä»¶ç»§ç»­ä¼ æ’­

    async def terminate(self):
        """æ’ä»¶é”€æ¯ï¼šå–æ¶ˆåå°ä»»åŠ¡ã€å…³é—­ HTTP session"""
        if self._update_task and not self._update_task.done():
            self._update_task.cancel()
            try:
                await self._update_task
            except (asyncio.CancelledError, Exception):
                pass
            self._update_task = None
        if self._session and not self._session.closed:
            await self._session.close()
            self._session = None
